# LoRA Data Toolkit

A **dead-simple Windows desktop app** for collecting training data from multiple sources and fine-tuning local LLMs with LoRA â€” all from one interface.

Built with Python + CustomTkinter. Dark OLED theme. No cloud, no subscriptions â€” everything runs locally.

![Python](https://img.shields.io/badge/Python-3.11+-blue?logo=python&logoColor=white)
![Platform](https://img.shields.io/badge/Platform-Windows-0078D4?logo=windows&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green)

---

## What It Does

```
Collect Data  â†’  Organize  â†’  Export  â†’  Train LoRA  â†’  Import to Ollama
```

### ğŸ“¥ Data Collection (7 sources)
| Source | Description |
|--------|------------|
| ğŸŒ **Web Scraper** | Extract clean text from any URL (trafilatura + BS4 fallback) |
| âš¡ **Bulk Scraper** | Paste 100+ URLs, scrape them all at once |
| ğŸ•· **Site Crawler** | BFS depth crawler â€” crawl entire sites with rate limiting |
| ğŸ“º **YouTube** | Pull transcripts + metadata from YouTube videos |
| ğŸ“‹ **Paste Text** | Manually paste text, notes, documentation |
| ğŸ“¸ **Screenshot OCR** | Extract text from images/screenshots (Tesseract) |
| ğŸ“ **Import Files** | Drag-and-drop PDF, TXT, MD, HTML, JSON, CSV, code files |

### ğŸ“š Data Management
- **Library** â€” Browse, search, edit, score, and delete entries
- **Quality Scoring** â€” Auto-score entries 0-100 for LoRA training quality
- **Duplicate Detection** â€” Finds similar titles before adding
- **Export** â€” 5 LoRA-ready formats: Alpaca, ShareGPT, Completion, ChatML, Raw JSON

### ğŸ§¬ Training
- **LoRA Fine-Tuning** â€” Real training with Unsloth on your NVIDIA GPU
- **Auto Model Resolution** â€” Pick your Ollama model â†’ auto-detects the HuggingFace source weights
- **Abliterated Model Support** â€” Prefers abliterated HF repos when source model is abliterated (huihui-ai, etc.)
- **Context Injection** â€” Quick hack: paste data into system prompt (honest about what it is)
- **VRAM Guide** â€” Shows what models fit your GPU

### ğŸ”€ Model Merging
- **5 merge methods** â€” SLERP, Linear, TIES, DARE-TIES, Passthrough
- **mergekit** wrapper with YAML config generation
- **GGUF conversion** + Ollama Modelfile generation

### ğŸ–¥ï¸ System Setup
- **GPU Auto-Detection** â€” Finds your NVIDIA GPU, shows VRAM, driver info
- **One-Click Dependency Install** â€” Installs PyTorch+CUDA, Unsloth, and all training deps
- **Smart Messaging** â€” If no GPU, explains that only context injection is available

---

## Screenshots

*Dark OLED theme with Windows 11 Mica titlebar*

---

## Quick Start

### Prerequisites
- **Python 3.11+** (3.12 recommended)
- **Windows 10/11**
- **Ollama** installed ([ollama.com](https://ollama.com)) for running local models

### Option 1: Setup Script
```bat
git clone https://github.com/YOUR_USERNAME/lora-data-toolkit.git
cd lora-data-toolkit
setup.bat
```

### Option 2: Manual
```bash
git clone https://github.com/YOUR_USERNAME/lora-data-toolkit.git
cd lora-data-toolkit
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
python main.py
```

### For LoRA Training (optional)
If you have an **NVIDIA GPU**, go to **Setup / GPU** page in the app and click **"Install Training"** to auto-install:
- PyTorch with CUDA 12.4
- Unsloth (fast LoRA)
- Transformers, PEFT, TRL, Datasets, etc.

Or install manually:
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
pip install "unsloth[cu124-torch250] @ git+https://github.com/unslothai/unsloth.git"
pip install peft transformers trl datasets accelerate bitsandbytes sentencepiece protobuf
```

---

## Project Structure

```
lora-data-toolkit/
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ config.py               # App configuration
â”œâ”€â”€ requirements.txt        # Core dependencies
â”œâ”€â”€ setup.bat               # Windows setup script
â”‚
â”œâ”€â”€ core/                   # Backend logic
â”‚   â”œâ”€â”€ database.py         # SQLite CRUD
â”‚   â”œâ”€â”€ scraper.py          # Web scraping (trafilatura + BS4)
â”‚   â”œâ”€â”€ github_scraper.py   # GitHub-specific scraper
â”‚   â”œâ”€â”€ youtube.py          # YouTube transcript extraction
â”‚   â”œâ”€â”€ site_crawler.py     # BFS depth crawler
â”‚   â”œâ”€â”€ exporter.py         # 5 LoRA export formats
â”‚   â”œâ”€â”€ merger.py           # Model merging (mergekit wrapper)
â”‚   â”œâ”€â”€ quality.py          # Training data quality scoring
â”‚   â”œâ”€â”€ file_reader.py      # PDF, TXT, MD, HTML, JSON, CSV reader
â”‚   â”œâ”€â”€ ocr.py              # Screenshot OCR (Tesseract)
â”‚   â”œâ”€â”€ settings.py         # JSON settings manager
â”‚   â”œâ”€â”€ tray.py             # System tray
â”‚   â””â”€â”€ hotkeys.py          # Global hotkeys
â”‚
â”œâ”€â”€ gui/                    # Frontend
â”‚   â”œâ”€â”€ app.py              # Main window + sidebar navigation
â”‚   â”œâ”€â”€ theme.py            # OLED dark theme colors/fonts
â”‚   â”œâ”€â”€ widgets.py          # Reusable widgets (Tooltip, StatusBar, etc.)
â”‚   â””â”€â”€ pages/              # 14 page views
â”‚       â”œâ”€â”€ scraper_page.py
â”‚       â”œâ”€â”€ bulk_scraper_page.py
â”‚       â”œâ”€â”€ site_crawler_page.py
â”‚       â”œâ”€â”€ youtube_page.py
â”‚       â”œâ”€â”€ paste_page.py
â”‚       â”œâ”€â”€ ocr_page.py
â”‚       â”œâ”€â”€ import_page.py
â”‚       â”œâ”€â”€ library_page.py
â”‚       â”œâ”€â”€ export_page.py
â”‚       â”œâ”€â”€ training_page.py    # LoRA training + HF auto-resolution
â”‚       â”œâ”€â”€ merge_page.py       # Model merging
â”‚       â”œâ”€â”€ setup_page.py       # GPU detection + dep installer
â”‚       â””â”€â”€ settings_page.py
â”‚
â””â”€â”€ data/                   # Runtime data (gitignored)
    â”œâ”€â”€ toolkit.db          # SQLite database
    â”œâ”€â”€ exports/            # Exported training files
    â””â”€â”€ settings.json       # User preferences
```

---

## Training Workflow

1. **Collect data** using any of the 7 sources
2. **Review** in the Data Library â€” edit, score, remove low-quality entries
3. **Export** as Alpaca JSONL format â†’ `data/exports/training_data.jsonl`
4. Go to **Train Model** page
5. **Select your Ollama model** (e.g. `huihui_ai/qwen3-abliterated:14b`)
6. App auto-resolves â†’ `huihui-ai/Qwen3-14B-abliterated` (abliterated HF repo!)
7. **Configure** LoRA params (rank, alpha, epochs, etc.)
8. **Generate + Launch** â†’ training runs in a new console
9. After training â†’ **import to Ollama** and run your fine-tuned model

### Supported Model Families
Auto-mapping works for: **Qwen3, Qwen2.5, Llama 3/3.1/3.2, Gemma 2/3, Mistral, Mixtral, DeepSeek, Phi-3/4, Dolphin** â€” including abliterated/uncensored variants.

---

## VRAM Requirements (4-bit QLoRA)

| VRAM | Model Size | Examples |
|------|-----------|----------|
| 4 GB | 1B-3B | Phi-3 Mini, Qwen2.5-3B |
| 8 GB | 7B-8B | Mistral-7B, Llama 3.1-8B |
| 12 GB | 9B-14B | Gemma-3-12B, Qwen3-14B |
| 16 GB | 14B-27B | Qwen3-14B âœ“, Gemma-3-27B |
| 24 GB | 30B-32B | Qwen2.5-32B, Qwen3-30B-A3B |
| 48 GB | 70B | Llama 3.1-70B |

---

## Tech Stack

- **Python 3.12** + **CustomTkinter** â€” Native-feeling dark UI
- **SQLite** â€” Local database, zero config
- **trafilatura** + **BeautifulSoup4** â€” Web scraping
- **youtube-transcript-api** â€” YouTube transcripts
- **Tesseract OCR** â€” Screenshot text extraction
- **Unsloth** â€” Fast LoRA fine-tuning
- **mergekit** â€” Model merging
- **pystray** â€” System tray
- **Windows 11 Mica** â€” Dark titlebar via DWM API

---

## License

MIT â€” do whatever you want with it.

---

## Contributing

Pull requests welcome. This started as a personal tool for collecting game security / cheat detection training data, but it works for any domain.
